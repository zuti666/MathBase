#  频率与概率

[TOC]



# 频率与概率

频率，描述了事件发生的频繁程度

## 频率定义

在相同的条件下，进行了$n$次试验，在这$n$次试验，在这$n$次试验中，事件$A$发生的次数$n_A$称为事件$A$发生的**频数**。比值$n_A/n$称为事件$A$发生的**频率**，并记为$f_n(A)$

由定义，易见频率具有以下基本性质：

1. $0 \leq f_n(A) \leq 1$
2. $f_n(S)=1$
3. 若$A_1,A_2,\cdots,A_k$是两两互不相容的事件，则$f_n(A_1 \cup A_2\cup  \cdots\cup A_k)=f_n(A_1)+f_n(A_2)+\cdots+f_n(A_n)$

事件$A$发生的频率是它发生的次数与试验次数之比，其大小表示$A$发生的频繁程度。

> 大量试验证实,当重复试验的次数n逐渐增大时,频率$f_n(A)$呈现出稳定性,逐渐稳定于某个常数.这种“频率稳定性”即通常所说的统计规律性。我们让试验重复大量次数,计算频率$f_n(A)$,以它来表征事件A发生可能性的大小.是合适的.
> 		但是，在实际中,我们不可能对每一个事件都做大量的试验,然后求得事件的频率,用以表征事件发生可能性的大小.同时,为了理论研究的需要,我们从频率的稳定性和频率的性质得到启发,给出如下表征事件发生可能性大小的概率的定义.



## 概率定义

设$E$是随机试验，$S$是它的样本空间。对于$E$的每一事件$A$赋予一个实数，记为$P(A)$，称为事件$A$的概率，如果集合函数$P(\cdot)$满足下列条件：

1. **非负性**： 对于每一个事件$A$，有$P(A)\geq 0$

2. **规范性** ： 对于必然事件$S$，有$P(S)=1$

3. **可列可加性**： 设$A_1,A_2,\cdots$是两两互不相容的事件，即对于$A_iA_j=\empty,i\neq j,i,j=1,2,\cdots$有

   $P(A_1\cup A_2 \cup \cdots )=P(A_1)+P(A_2)+\cdots$

>可以证明，当n→∞时频率$f_n(A)$在一定意义下接近于概率P(A).基于这一事实,我们就有理由将概率P(A)用来表征事件A在一次试验中发生的可能性的大小.



# 实际推断原理

人们在长期的实践中总结得到“**概率很小的事件在==一次试验==中实际上几乎是不发生的**"(称之为实**际推断原理**)。

# 切比雪夫不等式

**定理** 设随机变量$X$具有数学期望$E(X)=\mu$，方差$D(X)=\delta^2$。则对于任意正数$\epsilon$，不等式
$$
P\{ |X-\mu| \geq \epsilon\} \leq \frac{\delta^2}{\epsilon^2}
$$

> 切比雪夫不等式给出了在随机变量的分布未知,而只知道$E(X)$和$D(X)$的情况下估计概率$P\{|X- E(X)|<\epsilon\}$的界限。

# 大数定律

**弱大数定理**（辛钦大数定理） 设$X_1,X_2,\cdots$是**相互独立，服从同一分布**的随机变量序列，且具有数学期望$E(X_k)=\mu(k=1,2,\cdots)$。作前$n$个变量的算术平均$\frac{1}{n}\sum_{k=1}^{n}X_k$，则对于任意$\epsilon >0 $，有
$$
\lim_{n \rightarrow \infty} P\{ |\frac{1}{n}\sum_{k=1}^nX_k-\mu|<\epsilon\}=1 \ \ (1.1)
$$
$\{|\frac{1}{n} \sum_{k=1}^n X_k - \mu|<\epsilon\}$是一个随机事件。等式$(1.1)$式表明，当$n \rightarrow \infty$这个事件的趋势趋于1。即对于任意正数$\epsilon$，当$n$充分大时，不等式$|\frac{1}{n}\sum_{k=1}^nX_k-\mu|<\epsilon$成立的概率很大。通俗地说，辛钦大数定理是说，对于**独立同分布且具有均值$\mu$的随机变量**$X_1,\cdots,X_n$，**当$n$很大时它的算术平均$\frac{1}{n} \sum_{k=1}^n X_k$很可能接近于$\mu$。**

设$Y_1,Y_2,\cdots,Y_n,\cdots$是一个随机变量序列，$a$是一个常数。若对于任意正数$\epsilon$，有
$$
\lim_{n \rightarrow \infty} \{|Y_n - a|< \epsilon\}=1
$$
则称序列$Y_1,Y_2,\cdots,Y_n,\cdots$**依概率收敛于$a$** ,记为$Y_n \rightarrow^P a$

依概率收敛的序列有以下的性质：设$X_n \rightarrow^P a ,Y_n \rightarrow^P b$ 。又设函数$g(x,y)$在点$(a,b)$连续，则$g(X_n,Y_n) \rightarrow^P g(a,b)$

这样，上述定理又可以叙述为

**弱大数定理**（辛钦大数定理） 设随机变量$X_1,X_2,\cdots$是**相互独立，服从同一分布**且具有数学期望$E(X_k)=\mu (k=1,2,\cdots)$，则序列$\bar{X}=\frac{1}{n}\sum_{k=1}^n X_k$依概率收敛于$\mu$,即$\bar{X} \rightarrow^P \mu$。

**伯努利大数定理**  设$f_A$是$n$次独立重复试验中事件$A$发生的次数，$p$是事件$A$在每次试验中发生的概率，则对于任意正数$\epsilon > 0$，有
$$
\lim_{n \rightarrow \infty}P \{ |\frac{f_A}{n}-p|< \epsilon\}=1  \ \ (1.2)\\
或 \lim_{n \rightarrow \infty}P \{ |\frac{f_A}{n}-p| \geq \epsilon\}=0  \ \ (1.2')
$$

> 伯努利大数定理的结果表明,
>
> 对于任意ε>0,只要重复独立试验的次数n充分大,事件$ \{ |\frac{f_A}{n}-p| \geq \epsilon\}$是一个小概率事件。由实际推断原理知，这一事件实际上几乎是不发生的，
>
> 即在n充分大时事件$ \{ |\frac{f_A}{n}-p| \geq \epsilon\}$实际上几乎是必定要发生的。
>
> 亦即**对于给定的任意小的正数ε,在n充分大时,事件“频率$\frac{f_A}{n}$与概率p的偏差小于$\epsilon$”实际上几乎是必定要发生的**。这就是我们所说的频率稳定性的真正含义。
>
> 由实际推断原理,**在实际应用中,当试验次数很大时,便可以用事件的频率来代替事件的概率**。

# 中心极限定理

![image-20220316204318028](https://zuti.oss-cn-qingdao.aliyuncs.com/img/image-20220316204318028.png)

![image-20220316204406905](https://zuti.oss-cn-qingdao.aliyuncs.com/img/image-20220316204406905.png)

# 概率论与数理统计

概率论是已知总体服从什么分布，从而推断出这个分布有什么样的性质，比如已知分布，求期望方差；

数理统计好比总体是未知的，通过从总体中抽取的样本，**目的**是来推断总体具有什么样的特点。数理统计的研究内容主要分为两大类：

1. **试验设计**，即研究如何对随机现象进行观察和试验，以便更合理更有效地获得试验数据；
2. **统计推断**，即研究如何对所获得的有限数据进行整理和加工，并对所考察的对象的某些性质做出尽可能精确可靠的判断。



